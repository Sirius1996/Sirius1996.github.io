<!DOCTYPE html><html><head><meta name="generator" content="Hexo 3.8.0"><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> Semi-Supervised Classification with Graph Convolutional Networks 笔记 · Hexo</title><meta name="description" content="Semi-Supervised Classification with Graph Convolutional Networks 笔记 - Zidi Chen"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="search" type="application/opensearchdescription+xml" href="http://yoursite.com/atom.xml" title="Hexo"></head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/favicon.png" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="https://weibo.com/u/5519474336" target="_blank" class="nav-list-link">WEIBO</a></li><li class="nav-list-item"><a href="https://github.com/Sirius1996" target="_blank" class="nav-list-link">GITHUB</a></li><li class="nav-list-item"><a href="https://www.linkedin.com/in/%E5%AD%90%E8%BF%AA-%E9%99%88-43010911a/" target="_blank" class="nav-list-link">LINKEDIN</a></li></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">Semi-Supervised Classification with Graph Convolutional Networks 笔记</h1><div class="post-info">Mar 15, 2019</div><div class="post-content"><h3 id="introduction"><a class="markdownIt-Anchor" href="#introduction"></a> Introduction</h3>
<p>本篇文章的主要工作是将卷积扩展到图结构的数据中，能够得到比较好的数据表示，并且在半监督任务中也取得了不错的效果。该网络是传统卷积算法在图结构数据上的一个变体，可以直接用于处理图结构数据。从本质上讲，GCN 是谱图卷积（spectral graph convolution） 的<strong>局部一阶近似</strong>（localized first-order approximation）。GCN的另一个特点在于其模型规模会随图中边的数量的增长而线性增长。总的来说，GCN 可以用于对<strong>局部</strong>图结构与节点特征进行编码。<br>
使用神经网络模型 f(X,A) 对所有带标签节点进行基于监督损失的训练。其中，X为输入数据，A为图的邻接矩阵。<br>
在图的邻接矩阵上调整 f(⋅)将允许模型从监督损失 L0 中分配梯度信息，并使其能够学习所有节点（带标签或不带标签）的表示。</p>
<h3 id="图卷积神经网络"><a class="markdownIt-Anchor" href="#图卷积神经网络"></a> 图卷积神经网络</h3>
<p>本文得到了图卷积神经网络的（单层）最终形式：</p>
<p><img src="/2019/03/15/Semi-Supervised-Classification-with-Graph-Convolutional-Networks-笔记/image-20190313215108219.png" alt="image-20190313215108219"></p>
<h3 id="model"><a class="markdownIt-Anchor" href="#model"></a> <strong>Model</strong></h3>
<p>对于一个大图（例如“文献引用网络”），我们有时需要对其上的节点进行分类。然而，在该图上，仅有少量的节点是有标注的。此时，我们需要依靠这些已标注的节点来对那些没有标注过的节点进行分类，此即半监督节点分类问题。在这类问题中，由于大部分节点都没有已标注的标签，因此往往需要使用某种形式的图正则项对标签信息进行平滑（例如在损失函数中引入图拉普拉斯正则）。</p>
<p><img src="/2019/03/15/Semi-Supervised-Classification-with-Graph-Convolutional-Networks-笔记/image-20190313215221921.png" alt="image-20190313215221921"></p>
<p>其中， <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BL%7D_%7B0%7D" alt="\mathcal{L}_{0}"> 表示有监督的损失， <img src="https://www.zhihu.com/equation?tex=f%28%C2%B7%29" alt="f(·)"> 可以是一个类似于神经网络的可微函数。 <img src="https://www.zhihu.com/equation?tex=%5Clambda" alt="\lambda"> 表示一个权值因子， <img src="https://www.zhihu.com/equation?tex=X" alt="X"> 则是相应的节点向量表示。 <img src="https://www.zhihu.com/equation?tex=%5CDelta%3DD-A" alt="\Delta=D-A"> 表示未归一化的图拉普拉斯矩阵。这种处理方式的一个基本假设是：<strong>相连的节点可能有相同的标签</strong>。然而，这种假设却往往会限制模型的表示能力，因为图中的边不仅仅可以用于编码节点相似度，而且还包含有额外的信息。</p>
<p>GCN的使用可以有效地避开这一问题。GCN通过一个简单的映射函数 <img src="https://www.zhihu.com/equation?tex=f%28X%2CA%29" alt="f(X,A)"> ，可以将节点的局部信息汇聚到该节点中，然后仅使用那些有标注的节点计算 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BL%7D_%7B0%7D" alt="\mathcal{L}_{0}"> 即可，从而无需使用图拉普拉斯正则。</p>
<p>具体来说，本文使用了一个两层的GCN进行节点分类。模型结构图如下图所示：</p>
<p><img src="/2019/03/15/Semi-Supervised-Classification-with-Graph-Convolutional-Networks-笔记/image-20190313215334296.png" alt="image-20190313215334296"></p>
<p>其具体流程为：</p>
<ul>
<li>
<p>首先获取节点的特征表示 <img src="https://www.zhihu.com/equation?tex=X" alt="X"> 并计算邻接矩阵。</p>
</li>
<li>
<p>将其输入到一个两层的GCN网络中，得到每个标签的预测结果：</p>
<p><img src="/2019/03/15/Semi-Supervised-Classification-with-Graph-Convolutional-Networks-笔记/image-20190313215548648.png" alt="image-20190313215548648"></p>
<p>其中， <img src="https://www.zhihu.com/equation?tex=W%5E%7B%280%29%7D%5Cin%5Cmathbb%7BR%7D%5E%7BC%5Ctimes+H%7D" alt="W{(0)}\in\mathbb{R}{C\times H}"> 为第一层的权值矩阵，用于将节点的特征表示映射为相应的隐层状态。 <img src="https://www.zhihu.com/equation?tex=W%5E%7B%281%29%7D%5Cin%5Cmathbb%7BR%7D%5E%7BH%5Ctimes+F%7D" alt="W{(1)}\in\mathbb{R}{H\times F}"> 为第二层的权值矩阵，用于将节点的隐层表示映射为相应的输出（ <img src="https://www.zhihu.com/equation?tex=F" alt="F"> 对应节点标签的数量）。最后将每个节点的表示通过一个softmax函数，即可得到每个标签的预测结果。</p>
<p>对于半监督分类问题，使用所有有标签节点上的期望交叉熵作为损失函数：</p>
<p><img src="/2019/03/15/Semi-Supervised-Classification-with-Graph-Convolutional-Networks-笔记/image-20190313215528339.png" alt="image-20190313215528339"></p>
<p>其中， <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BY%7D_%7BL%7D" alt="\mathcal{Y}_{L}"> 表示有标签的节点集。</p>
</li>
</ul>
</div></article></div></main><footer><div class="paginator"><a href="/2019/03/19/Inductive-Representation-Learning-on-Large-Graphs-笔记/" class="prev">PREV</a><a href="/2019/03/15/DeepWalk-Online-Learning-of-Social-Representations-笔记/" class="next">NEXT</a></div><div class="copyright"><p>© 2019 <a href="http://yoursite.com">Zidi Chen</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">hexo-theme-apollo</a>.</p></div></footer></div><script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" integrity="sha384-crwIf/BuaWM9rM65iM+dWFldgQ1Un8jWZMuh3puxb8TOY9+linwLoI7ZHZT+aekW" crossorigin="anonymous"></script></body></html>